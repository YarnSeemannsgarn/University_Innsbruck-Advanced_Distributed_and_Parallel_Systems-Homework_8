%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 3.1 (25/3/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Linux and Unix Users Group at Virginia Tech Wiki 
% (https://vtluug.org/wiki/Example_LaTeX_chem_lab_report)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

%\usepackage[version=3]{mhchem} % Package for chemical equation typesetting
%\usepackage{siunitx} % Provides the \SI{}{} and \si{} command for typesetting SI units
\usepackage{graphicx} % Required for the inclusion of images
%\usepackage{natbib} % Required to change bibliography style to APA
%\usepackage{amsmath} % Required for some math elements 
\usepackage{listings}
\lstset{
  breaklines=true,
  basicstyle=\scriptsize,
  columns=fullflexible
}

\usepackage{tikz}

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

%\usepackage{times} % Uncomment to use the Times New Roman font

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Report: Homework 8 - MapReduce (Hadoop) with Povray}% Title

\author{Jan \textsc{Schlenker} \& Sebastian \textsc{Sams}} % Author name

\date{\today} % Date for the report

\begin{document}

\maketitle % Insert the title, author and date

\begin{center}
\begin{tabular}{l l}
Instructor: & Dipl.-Ing. Dr. Simon Ostermann \\
Programming language: & Java \\
Library used: & Hadoop 2.4.0 \& Java AWS SDK 1.1.0 \\
Total points: & 50 \\
\end{tabular}
\end{center}

% If you wish to include an abstract, uncomment the lines below
% \begin{abstract}
% Abstract text
% \end{abstract}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Prerequirements}

\begin{itemize}
\item Java 1.7
\item Maven 3.0.5
\end{itemize}

\section{How to run the programme}

First of all extract the archive file homework\_8.tar.gz:

\begin{lstlisting}[language=bash, deletekeywords={cd}]
  $ tar -xzf homework_8.tar.gz
  $ cd homework_8
\end{lstlisting}

The programme allows to render Povray files on a Hadoop cluster.
It is splitted into two subprogrammes:

\begin{enumerate}
\item map-reduce-povray: contains the the implementation of the Mapper and the Reducer
\item map-reduce-povray-ui: contains a gui implementation to start a MapReduce job in an AWS Elastic MapReduce (EMR) cluster
\end{enumerate}

First of all build all projects:

\begin{lstlisting}[language=bash, deletekeywords={cd}]
  $ mvn clean install
\end{lstlisting}

The map-reduce-povray programme can be executed on a local Hadoop cluster via:

\begin{lstlisting}[language=bash, deletekeywords={cd}]
  $ $HADOOP_HOME/bin/hadoop jar map-reduce-povray/target/map-reduce-povray-1.0.jar mapReducePovray.Povray <input-dir> <output-dir> <uri-of-pov-file>
\end{lstlisting}

The programme can also be executed on Amazon EMR. A small user interface for using it via EMR is available in the project map-reduce-povray-ui. Required preparations before running the user interface (applies to both the command line and GUI version):

\begin{itemize}
\item Create an EMR cluster, note the cluster ID
\item Create an S3 bucket and upload the jar-file containing the map-reduce implementation
\item Create access credentials which have permissions to create and monitor steps on the cluster and can list and edit files on the S3 bucket. Store them in a properties file called "AwsCredentials.properties" as entries named accessKey and secretKey.
\end{itemize}

The map-reduce-povray-ui gui programme can be executed via:

\begin{lstlisting}[language=bash, deletekeywords={cd}]
  $ cd map-reduce-povray-ui
  $ mvn exec:java
\end{lstlisting}

\section{Programme explanation}

Figure~\ref{fig:map-reduce-povray-workflow} shows the MapReduce (Hadoop) workflow for Povray.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{map-reduce-povray-workflow.png}
\caption{MapReduce (Hadoop) workflow for Povray}
\label{fig:map-reduce-povray-workflow}
\end{center}
\end{figure}

\subsection{Mapper}

The mapper processes take text files as input, whose first line must have the following structure:

\begin{lstlisting}[language=bash, deletekeywords={cd}]
  <start-frame> <end-frame> <subset-start-frame> <subset-end-frame>
\end{lstlisting}

Because the Povray file is part of the created jar, the mappers can simply create the subset-frames, pack them as FrameWritables (which is a custom implementation of the Mapper/Reducer output interface Writable) and output them one by one in the following format:

\begin{lstlisting}[language=bash, deletekeywords={cd}]
  1, FrameWritable(<frame-number>, "png", <bytes-of-frame>)
\end{lstlisting}

The key is always one, because one reducer is responsible for values with the same key and all pictures should be merged to one file.
The needed pov-file for the mapper processes is attached as a cache file by the main programme.

\subsection{Reducer (\& Combiner)}
In Hadoop the output of one mapper will first go into one combiner. The combiner works often as a pre-reducer and reduces the output of one mapper. In this programme the combiner and the reducer implementations are the same. The combiner first merges the rendered pictures of one mapper to a gif and outputs them to the shuffler. The shuffler on the other hand outputs all values with the same key to one reducer. Because there is only one key, the shuffler outputs always only one dataset, which contains all the pre-merged gifs. At last one reducer merges all pre-merged gifs to one.

\end{document}
